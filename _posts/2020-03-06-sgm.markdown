---
permalink: /sgm/
layout: post
title:  "Sparse Graphical Memory for Robust Planning"
date:   2020-03-06 11:10:11 -0800
image: /images/cleanup.gif
categories: research
affiliation: UC Berkeley, FAIR
authors: "<b>Michael Laskin*</b>, Scott Emmons*, Ajay Jain*, Thanard Kurutach, Pieter Abbeel, Deepak Pathak"
venue: "In Submission"
code: https://github.com/scottemmons/sgm
arxiv: http://arxiv.org/abs/2003.06417
video: https://youtube.com/embed/n3F3i7F3Lcg
equal: '*'
summary: Introduced novel state aggregation criterium - <i> two-way consistency (TWC) </i> - and utilized it to make any semi-parametric graphical method more robust. Proved theoretically that TWC enables near-optimal search.

---

<script>
function myFunction() {
  var x = document.getElementById("bibtex");
  if (x.style.display === "none") {
    x.style.display = "block";
  } else {
    x.style.display = "none";
  }
}
function showTweet() {
  var x = document.getElementById("twitter");
  if (x.style.display === "none") {
    x.style.display = "block";
  } else {
    x.style.display = "none";
  }
}
</script>
# Sparse Graphical Memory for Robust Planning
<br> 

<div class="table-like" style="justify-content:space-evenly;max-width:800px;margin:;">
      <div><span class='author_name'><a href="https://mishalaskin.github.io/" target="_blank">M. Laskin*</a></span>
      <br>
      <span class='author_name'>UC Berkeley</span>
      </div>
      <div><span class='author_name'><a href="http://scottemmons.com/" target="_blank">S. Emmons*</a></span>
      <br>
      <span class='author_name'>UC Berkeley</span>
      </div>

      <div><span class='author_name'><a href="https://www.ajayjain.net/" target="_blank">A. Jain*</a></span>
      <br>
      <span class='author_name'>UC Berkeley</span>
      </div>
    
      <div><span class='author_name'><a href="http://people.eecs.berkeley.edu/~thanard.kurutach/" target="_blank">T. Kurutach</a></span>
      <br>
        <span class='author_name'>UC Berkeley</span>
        </div>

      <div><span class='author_name'><a href="https://people.eecs.berkeley.edu/~pabbeel/" target="_blank">P. Abbeel</a></span>
      <br><span class='author_name'>UC Berkeley</span>
      </div>

      <div><span class='author_name'><a href="https://people.eecs.berkeley.edu/~pathak/" target="_blank"> D. Pathak</a></span>
      <br><span class='author_name'>CMU, FAIR</span>
      </div>
</div>
<span>* equal contribution</span>

<br>

<p>
  Links ðŸ‘‰ <a   target='_blank' href="{{page.code}}"><u>Github Code</u></a>
        , <a  target='_blank' href="{{page.arxiv}}"><u> ArXiv Paper</u></a>
         , <a  onclick="myFunction()" href="#"><u> Cite BibTex</u></a>

</p>

<div style='display:none;font-size:12px' id="bibtex">
<pre>
@unpublished{laskin2020sparse,
  title={Sparse Graphical Memory for Robust Planning},
  author={Laskin, Michael and Emmons, Scott and Jain, Ajay and Kurutach, 
  Thanard and Abbeel, Pieter and Pathak, Deepak},
  note={arXiv:2003.06417}
}
</pre>
</div>


<br>


## Summary

To operate effectively in the real world, agents should be able to act from high-dimensional raw sensory input such as images and achieve diverse goals across long time-horizons.  Current deep reinforcement and imitation learning methods can learn directly from high-dimensional inputs but do not scale well to long-horizon tasks. 

In contrast, classical graphical methods like A* search are able to solve long-horizon tasks, but assume that the state space is abstracted away from raw sensory input. Recent works have attempted to combine the strengths of deep learning and classical planning, however, dominant methods in this domain are still quite brittle and scale poorly with the size of the environment. 

We introduce Sparse Graphical Memory (SGM), a new data structure that stores observations and feasible transitions in a sparse memory. SGM aggregates states according to a novel two-way consistency objective, adapting classic state aggregation criteria to goal-conditioned RL: two states are redundant when they are interchangeable both as goals and as starting states. We show that SGM significantly outperforms current state of the art methods on long horizon, sparse-reward visual navigation tasks.


## Method
<br>
<center>
<img class='hvr-grow' src="/images/sgm/sgm_overview.png" alt="" style="width:60%;"/>
</center>
<br>

Illustration of Sparse Graphical Memory (SGM) construction. As new observations are collected, they are either merged with the existing nodes of the graph or a new node is generated according to our two-way consistency criterion. Once the sparse graph is constructed, incorrect edges representing infeasible transitions between observations are corrected.


## Video 

Short 3 minute video explaining SGM.

<center>
<iframe width="560" height="315" src="https://www.youtube.com/embed/n3F3i7F3Lcg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</center>

<br>
<center><a  target='_blank' href="{{page.arxiv}}"><u> More details on ArXiv</u></a> </center>
<br>
<center>
<a  target='_blank' href="{{page.arxiv}}">
<img class='hvr-grow' src="/images/sgm/sgm_paper_thumbnail.png" alt="" style="width:80%;"/>
</a>
</center>

<br>
<hr>
<br>




